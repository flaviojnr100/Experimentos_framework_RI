{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5a998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Flavio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Flavio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Flavio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from unicodedata import normalize\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "\n",
    "import pyterrier as pt\n",
    "\n",
    "import time\n",
    "\n",
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edd4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672d500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca6d73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codProposicao</th>\n",
       "      <th>txtSiglaTipo</th>\n",
       "      <th>numAno</th>\n",
       "      <th>numNumero</th>\n",
       "      <th>txtNome</th>\n",
       "      <th>txtEmenta</th>\n",
       "      <th>txtExplicacaoEmenta</th>\n",
       "      <th>txtIndexacao</th>\n",
       "      <th>txtInteiroTeor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16357</td>\n",
       "      <td>PL</td>\n",
       "      <td>1999</td>\n",
       "      <td>1165</td>\n",
       "      <td>PL 1165/1999</td>\n",
       "      <td>Altera dispositivo da Lei nº 8.987, de 13 de f...</td>\n",
       "      <td>Estabelece que as concessionárias disponibiliz...</td>\n",
       "      <td>Alteração, Lei das Concessões de Serviços Públ...</td>\n",
       "      <td>Ofício nº 1416  (SF)                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19098</td>\n",
       "      <td>PL</td>\n",
       "      <td>1992</td>\n",
       "      <td>3097</td>\n",
       "      <td>PL 3097/1992</td>\n",
       "      <td>Dispõe sobre a eleição de diretores de fundos ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMAS, ELEIÇÃO DIRETA, EMPREGADO, APOSENTADO,...</td>\n",
       "      <td>COMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E DE REDAÇÃ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20464</td>\n",
       "      <td>PL</td>\n",
       "      <td>2000</td>\n",
       "      <td>3927</td>\n",
       "      <td>PL 3927/2000</td>\n",
       "      <td>Altera a composição dos Tribunais Regionais do...</td>\n",
       "      <td>Altera a composição do TRT da 5ª região, 6ª re...</td>\n",
       "      <td>Alteração, Lei Federal, composição, Tribunal R...</td>\n",
       "      <td>COMISSÃO DE TRABALHO, DE ADMINISTRAÇÃO E SERVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20683</td>\n",
       "      <td>PL</td>\n",
       "      <td>1998</td>\n",
       "      <td>4117</td>\n",
       "      <td>PL 4117/1998</td>\n",
       "      <td>Dispõe sobre o acesso a ambientes de uso colet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Autorização, pessoa portadora de deficiência, ...</td>\n",
       "      <td>Câmara dos Deputados\\n           Departamento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20857</td>\n",
       "      <td>PL</td>\n",
       "      <td>1998</td>\n",
       "      <td>4395</td>\n",
       "      <td>PL 4395/1998</td>\n",
       "      <td>Estabelece as Diretrizes Nacionais de Defesa C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fixação, diretrizes, defesa civil, (Sindec), d...</td>\n",
       "      <td>- 1 - \\nCOMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57104</th>\n",
       "      <td>2358873</td>\n",
       "      <td>PL</td>\n",
       "      <td>2023</td>\n",
       "      <td>2233</td>\n",
       "      <td>PL 2233/2023</td>\n",
       "      <td>Altera o parágrafo único do art. 71 do Código ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 \\n  \\n \\n \\n \\nCÂMARA DOS DEPUTADOS \\nPROJET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57105</th>\n",
       "      <td>2358874</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>3616</td>\n",
       "      <td>PL 3616/2019</td>\n",
       "      <td>Altera a Lei nº 9.503, de 23 de setembro de 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 9.503, de 23 de setembro\\nde 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57106</th>\n",
       "      <td>2358875</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>1822</td>\n",
       "      <td>PL 1822/2019</td>\n",
       "      <td>Altera a Lei nº 11.340, de 7 de agosto de 2006...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 11.340, de 7 de agosto de\\n200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57107</th>\n",
       "      <td>2358877</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>3815</td>\n",
       "      <td>PL 3815/2019</td>\n",
       "      <td>Altera a Lei nº 7.565, de 19 de dezembro de 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 7.565, de 19 de dezembro\\nde  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>2358878</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>3130</td>\n",
       "      <td>PL 3130/2019</td>\n",
       "      <td>Altera a Lei nº 13.675, de 11 de junho de 2018...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 13.675, de 11 de junho de\\n201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57109 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       codProposicao txtSiglaTipo  numAno  numNumero       txtNome  \\\n",
       "0              16357   PL            1999       1165  PL 1165/1999   \n",
       "1              19098   PL            1992       3097  PL 3097/1992   \n",
       "2              20464   PL            2000       3927  PL 3927/2000   \n",
       "3              20683   PL            1998       4117  PL 4117/1998   \n",
       "4              20857   PL            1998       4395  PL 4395/1998   \n",
       "...              ...          ...     ...        ...           ...   \n",
       "57104        2358873   PL            2023       2233  PL 2233/2023   \n",
       "57105        2358874   PL            2019       3616  PL 3616/2019   \n",
       "57106        2358875   PL            2019       1822  PL 1822/2019   \n",
       "57107        2358877   PL            2019       3815  PL 3815/2019   \n",
       "57108        2358878   PL            2019       3130  PL 3130/2019   \n",
       "\n",
       "                                               txtEmenta  \\\n",
       "0      Altera dispositivo da Lei nº 8.987, de 13 de f...   \n",
       "1      Dispõe sobre a eleição de diretores de fundos ...   \n",
       "2      Altera a composição dos Tribunais Regionais do...   \n",
       "3      Dispõe sobre o acesso a ambientes de uso colet...   \n",
       "4      Estabelece as Diretrizes Nacionais de Defesa C...   \n",
       "...                                                  ...   \n",
       "57104  Altera o parágrafo único do art. 71 do Código ...   \n",
       "57105  Altera a Lei nº 9.503, de 23 de setembro de 19...   \n",
       "57106  Altera a Lei nº 11.340, de 7 de agosto de 2006...   \n",
       "57107  Altera a Lei nº 7.565, de 19 de dezembro de 19...   \n",
       "57108  Altera a Lei nº 13.675, de 11 de junho de 2018...   \n",
       "\n",
       "                                     txtExplicacaoEmenta  \\\n",
       "0      Estabelece que as concessionárias disponibiliz...   \n",
       "1                                                    NaN   \n",
       "2      Altera a composição do TRT da 5ª região, 6ª re...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "57104                                                NaN   \n",
       "57105                                                NaN   \n",
       "57106                                                NaN   \n",
       "57107                                                NaN   \n",
       "57108                                                NaN   \n",
       "\n",
       "                                            txtIndexacao  \\\n",
       "0      Alteração, Lei das Concessões de Serviços Públ...   \n",
       "1      NORMAS, ELEIÇÃO DIRETA, EMPREGADO, APOSENTADO,...   \n",
       "2      Alteração, Lei Federal, composição, Tribunal R...   \n",
       "3      Autorização, pessoa portadora de deficiência, ...   \n",
       "4      Fixação, diretrizes, defesa civil, (Sindec), d...   \n",
       "...                                                  ...   \n",
       "57104                                                NaN   \n",
       "57105                                                NaN   \n",
       "57106                                                NaN   \n",
       "57107                                                NaN   \n",
       "57108                                                NaN   \n",
       "\n",
       "                                          txtInteiroTeor  \n",
       "0      Ofício nº 1416  (SF)                          ...  \n",
       "1      COMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E DE REDAÇÃ...  \n",
       "2      COMISSÃO DE TRABALHO, DE ADMINISTRAÇÃO E SERVI...  \n",
       "3      Câmara dos Deputados\\n           Departamento ...  \n",
       "4      - 1 - \\nCOMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E D...  \n",
       "...                                                  ...  \n",
       "57104  1 \\n  \\n \\n \\n \\nCÂMARA DOS DEPUTADOS \\nPROJET...  \n",
       "57105  Altera a Lei nº 9.503, de 23 de setembro\\nde 1...  \n",
       "57106  Altera a Lei nº 11.340, de 7 de agosto de\\n200...  \n",
       "57107  Altera a Lei nº 7.565, de 19 de dezembro\\nde  ...  \n",
       "57108  Altera a Lei nº 13.675, de 11 de junho de\\n201...  \n",
       "\n",
       "[57109 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e37ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c52920",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b12bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7653ca77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txtNome</th>\n",
       "      <th>text</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PL 1165/1999</td>\n",
       "      <td>Alteração, Lei das Concessões de Serviços Públ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL 3097/1992</td>\n",
       "      <td>NORMAS, ELEIÇÃO DIRETA, EMPREGADO, APOSENTADO,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL 3927/2000</td>\n",
       "      <td>Alteração, Lei Federal, composição, Tribunal R...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PL 4117/1998</td>\n",
       "      <td>Autorização, pessoa portadora de deficiência, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PL 4395/1998</td>\n",
       "      <td>Fixação, diretrizes, defesa civil, (Sindec), d...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57104</th>\n",
       "      <td>PL 2233/2023</td>\n",
       "      <td>em branco</td>\n",
       "      <td>57104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57105</th>\n",
       "      <td>PL 3616/2019</td>\n",
       "      <td>em branco</td>\n",
       "      <td>57105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57106</th>\n",
       "      <td>PL 1822/2019</td>\n",
       "      <td>em branco</td>\n",
       "      <td>57106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57107</th>\n",
       "      <td>PL 3815/2019</td>\n",
       "      <td>em branco</td>\n",
       "      <td>57107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>PL 3130/2019</td>\n",
       "      <td>em branco</td>\n",
       "      <td>57108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            txtNome                                               text  docno\n",
       "0      PL 1165/1999  Alteração, Lei das Concessões de Serviços Públ...      0\n",
       "1      PL 3097/1992  NORMAS, ELEIÇÃO DIRETA, EMPREGADO, APOSENTADO,...      1\n",
       "2      PL 3927/2000  Alteração, Lei Federal, composição, Tribunal R...      2\n",
       "3      PL 4117/1998  Autorização, pessoa portadora de deficiência, ...      3\n",
       "4      PL 4395/1998  Fixação, diretrizes, defesa civil, (Sindec), d...      4\n",
       "...             ...                                                ...    ...\n",
       "57104  PL 2233/2023                                          em branco  57104\n",
       "57105  PL 3616/2019                                          em branco  57105\n",
       "57106  PL 1822/2019                                          em branco  57106\n",
       "57107  PL 3815/2019                                          em branco  57107\n",
       "57108  PL 3130/2019                                          em branco  57108\n",
       "\n",
       "[57109 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57970b",
   "metadata": {},
   "source": [
    "# Config 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeace8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa3c0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config1t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e1d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a104115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 17.336833\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd1d29",
   "metadata": {},
   "source": [
    "# Config 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dda7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9381d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6cd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89b87517",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bfea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "630fe354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [word for word in terms if word not in stopwords]\n",
    "    terms = \" \".join(terms)\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831e733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc3b34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txtNome</th>\n",
       "      <th>text</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PL 1165/1999</td>\n",
       "      <td>alteracao lei concessoes servicos publicos obr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL 3097/1992</td>\n",
       "      <td>normas eleicao direta empregado aposentado dir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL 3927/2000</td>\n",
       "      <td>alteracao lei federal composicao tribunal regi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PL 4117/1998</td>\n",
       "      <td>autorizacao pessoa portadora deficiencia defic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PL 4395/1998</td>\n",
       "      <td>fixacao diretrizes defesa civil sindec definic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57104</th>\n",
       "      <td>PL 2233/2023</td>\n",
       "      <td>branco</td>\n",
       "      <td>57104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57105</th>\n",
       "      <td>PL 3616/2019</td>\n",
       "      <td>branco</td>\n",
       "      <td>57105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57106</th>\n",
       "      <td>PL 1822/2019</td>\n",
       "      <td>branco</td>\n",
       "      <td>57106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57107</th>\n",
       "      <td>PL 3815/2019</td>\n",
       "      <td>branco</td>\n",
       "      <td>57107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>PL 3130/2019</td>\n",
       "      <td>branco</td>\n",
       "      <td>57108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            txtNome                                               text  docno\n",
       "0      PL 1165/1999  alteracao lei concessoes servicos publicos obr...      0\n",
       "1      PL 3097/1992  normas eleicao direta empregado aposentado dir...      1\n",
       "2      PL 3927/2000  alteracao lei federal composicao tribunal regi...      2\n",
       "3      PL 4117/1998  autorizacao pessoa portadora deficiencia defic...      3\n",
       "4      PL 4395/1998  fixacao diretrizes defesa civil sindec definic...      4\n",
       "...             ...                                                ...    ...\n",
       "57104  PL 2233/2023                                             branco  57104\n",
       "57105  PL 3616/2019                                             branco  57105\n",
       "57106  PL 1822/2019                                             branco  57106\n",
       "57107  PL 3815/2019                                             branco  57107\n",
       "57108  PL 3130/2019                                             branco  57108\n",
       "\n",
       "[57109 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ced0d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f38fbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config5t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89c6b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2ecba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 14.515021\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb05f7e",
   "metadata": {},
   "source": [
    "# Config 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b08b397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c03c100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea4bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ad51cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b17c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d2708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLPStemmer()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "        \n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72c60cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "281c8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99c3f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config8t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f29029b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd1f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 14.213581\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2add25",
   "metadata": {},
   "source": [
    "# Config 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb4e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Savoy:\n",
    "\n",
    "    def __removeAllPTAccent(self, old_word):\n",
    "        word = list(old_word)\n",
    "        len_word = len(word)-1\n",
    "        for i in range(len_word, -1, -1):\n",
    "            if word[i] == 'ä':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'â':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'à':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'á':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'ã':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'ê':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'é':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'è':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'ë':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'ï':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'î':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'ì':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'í':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'ü':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'ú':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'ù':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'û':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'ô':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ö':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ó':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ò':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'õ':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ç':\n",
    "                word[i] = 'c'\n",
    "\n",
    "        new_word = \"\".join(word)\n",
    "        return new_word\n",
    "\n",
    "    def __finalVowelPortuguese(self, word):\n",
    "        len_word = len(word)\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 'e' or word[-1] == 'a' or word[-1] == 'o':\n",
    "                word = word[:-1]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __remove_PTsuffix(self, word):\n",
    "        len_word = len(word)\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'e' and (word[-3] == 'r' or word[-3] == 's' or word[-3] == 'z' or word[-3] == 'l'):\n",
    "                word = word[:-2]\n",
    "                return word\n",
    "        if len_word > 2:\n",
    "            if word[-1] == 's' and word[-2] == 'n':\n",
    "                new_word = list(word)\n",
    "                new_word[-2] = 'm'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if (word[-1] == 's' and word[-2] == 'i') and (word[-3] == 'e' or word[-3] == 'é'):\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'e'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'i' and word[-3] == 'a':\n",
    "                new_word = list(word)\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'i' and word[-3] == 'ó':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'o'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                return sing\n",
    "\n",
    "        if len_word > 2:\n",
    "            if word[-1] == 's' and word[-2] == 'e' and word[-3] == 'õ':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'ã'\n",
    "                new_word[-2] = 'o'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "            if word[-1] == 's' and word[-2] == 'e' and word[-3] == 'ã':\n",
    "                new_word = list(word)\n",
    "                new_word[-2] = 'o'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 5:\n",
    "            if word[-1] == 'e' and word[-2] == 't' and word[-3] == 'n' and word[-4] == 'e' and word[-5] == 'm':\n",
    "                word = word[:-5]\n",
    "                return word\n",
    "\n",
    "        if len_word > 2:\n",
    "            if word[-1] == 's':\n",
    "                word = word[:-1]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __normFemininPortuguese(self, word):\n",
    "\n",
    "        len_word = len(word)\n",
    "\n",
    "        if len_word < 3 or word[-1] != 'a':\n",
    "            return word\n",
    "\n",
    "        if len_word > 6:\n",
    "\n",
    "            if word[-2] == 'h' and word[-3] == 'n' and word[-4] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'c' and word[-3] == 'a' and word[-4] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'r' and word[-3] == 'i' and word[-4] == 'e':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "        if len_word > 5:\n",
    "            if word[-2] == 'n' and word[-3] == 'o':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'ã'\n",
    "                new_word[-2] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                masc = masc[:-1]\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'r' and word[-3] == 'o':\n",
    "                word = word[:-1]\n",
    "                return word\n",
    "\n",
    "            if word[-2] == 's' and word[-3] == 'o':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 's' and word[-3] == 'e':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'ê'\n",
    "                masc = \"\".join(new_word)\n",
    "                masc = masc[:-1]\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'c' and word[-3] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'd' and word[-3] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'd' and word[-3] == 'a':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'v' and word[-3] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'm' and word[-3] == 'a':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'n':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "        return word\n",
    "\n",
    "    def stem(self, word):\n",
    "        len_word = len(word)\n",
    "        if len_word > 2:\n",
    "            word = self.__remove_PTsuffix(word)\n",
    "            word = self.__normFemininPortuguese(word)\n",
    "            word = self.__finalVowelPortuguese(word)\n",
    "            word = self.__removeAllPTAccent(word)\n",
    "\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df7c9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2916374",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b93c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82b00667",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa0c9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c27bdaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = Savoy()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "        \n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14725ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54897403",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config9t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e5156",
   "metadata": {},
   "source": [
    "# Config 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00bb70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f68c6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83f205a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0780e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d394e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8ea7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLPStemmer()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    ngram = []\n",
    "    ngram_1 = list(ngrams(terms, 1))\n",
    "    ngram_2 = list(ngrams(terms, 2))\n",
    "    for w in ngram_1:\n",
    "        ngram.append(w[0])\n",
    "        \n",
    "    for w in ngram_2:\n",
    "        string = w[0] + \"_\" + w[1]\n",
    "        ngram.append(string)\n",
    "    \n",
    "    return \" \".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94733b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64c61b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81589fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config18t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3403f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6392163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 17.367999\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c297b",
   "metadata": {},
   "source": [
    "# Config 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b2e1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc8a44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04bc8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71b09a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce57d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87e11cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = Savoy()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    ngram = []\n",
    "    ngram_1 = list(ngrams(terms, 1))\n",
    "    ngram_2 = list(ngrams(terms, 2))\n",
    "    for w in ngram_1:\n",
    "        ngram.append(w[0])\n",
    "        \n",
    "    for w in ngram_2:\n",
    "        string = w[0] + \"_\" + w[1]\n",
    "        ngram.append(string)\n",
    "    \n",
    "    return \" \".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12224052",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cb60fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config21t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffeb3ef",
   "metadata": {},
   "source": [
    "# Config 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68439df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSLP_S:\n",
    "    def __plural_reduction(self, word):\n",
    "        excep = [\"lápis\",\"cais\",\"mais\",\"crúcis\",\"biquínis\",\"pois\",\"depois\",\"dois\",\"leis\" ]\n",
    "        excep_s = [\"aliás\",\"pires\",\"lápis\",\"cais\",\"mais\",\"mas\",\"menos\", \"férias\",\"fezes\",\"pêsames\",\"crúcis\",\"gás\", \"atrás\",\"moisés\",\"através\",\"convés\",\"ês\", \"país\",\"após\",\"ambas\",\"ambos\",\"messias\"]\n",
    "\n",
    "        len_word = len(word)\n",
    "        new_word = list(word)\n",
    "\n",
    "        if len_word >= 3:\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'n':\n",
    "                new_word[-2] = 'm'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'õ':\n",
    "                new_word[-3] = 'ã'\n",
    "                new_word[-2] = 'o'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return  sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'ã':\n",
    "                if word == 'mães':\n",
    "                    word = word[:-1]\n",
    "                    return word\n",
    "                else:\n",
    "                    new_word[-2] = 'o'\n",
    "                    sing = \"\".join(new_word)\n",
    "                    sing = sing[:-1]\n",
    "                    return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'a':\n",
    "                if word != 'cais' and word != 'mais':\n",
    "                    new_word[-2] = 'l'\n",
    "                    sing = \"\".join(new_word)\n",
    "                    sing = sing[:-1]\n",
    "                    return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'é':\n",
    "                new_word[-3] = 'e'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'e':\n",
    "                new_word[-3] = 'e'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'ó':\n",
    "                new_word[-3] = 'o'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i':\n",
    "                if word not in excep:\n",
    "                    new_word[-1] = 'l'\n",
    "                    sing = \"\".join(new_word)\n",
    "                    return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'l':\n",
    "                word = word[:-2]\n",
    "                return word\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'r':\n",
    "                word = word[:-2]\n",
    "                return word\n",
    "\n",
    "            if new_word[-1] == 's':\n",
    "                if word not in excep_s:\n",
    "                    word = word[:-1]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def stem(self, word):\n",
    "        word = self.__plural_reduction(word)\n",
    "\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c956c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21bd01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eaa4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ae31a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a51cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "630b5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLP_S()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a02bb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe39d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config22t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7772b0c9",
   "metadata": {},
   "source": [
    "# Config 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c530b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f019b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8d4a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtIndexacao\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01a076d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.fillna(\"em branco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3877c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtIndexacao': 'text','id':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48bea5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLP_S()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    ngram = []\n",
    "    ngram_1 = list(ngrams(terms, 1))\n",
    "    ngram_2 = list(ngrams(terms, 2))\n",
    "    for w in ngram_1:\n",
    "        ngram.append(w[0])\n",
    "        \n",
    "    for w in ngram_2:\n",
    "        string = w[0] + \"_\" + w[1]\n",
    "        ngram.append(string)\n",
    "    \n",
    "    return \" \".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96c8a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"text\"] = dados1[\"text\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c65cfecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"E:\\Corpora_em_json\\experimentos_pyterrier\\config23t\",stemmer=None,stopwords=None,tokeniser=\"UTFTokeniser\")\n",
    "indexref2 = iter_indexer.index(dados1.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28400a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
