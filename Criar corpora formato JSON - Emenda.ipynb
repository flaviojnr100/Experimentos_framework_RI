{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0cf84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Flavio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Flavio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Flavio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from unicodedata import normalize\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50615748",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6187de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc027dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codProposicao</th>\n",
       "      <th>txtSiglaTipo</th>\n",
       "      <th>numAno</th>\n",
       "      <th>numNumero</th>\n",
       "      <th>txtNome</th>\n",
       "      <th>txtEmenta</th>\n",
       "      <th>txtExplicacaoEmenta</th>\n",
       "      <th>txtIndexacao</th>\n",
       "      <th>txtInteiroTeor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16357</td>\n",
       "      <td>PL</td>\n",
       "      <td>1999</td>\n",
       "      <td>1165</td>\n",
       "      <td>PL 1165/1999</td>\n",
       "      <td>Altera dispositivo da Lei nº 8.987, de 13 de f...</td>\n",
       "      <td>Estabelece que as concessionárias disponibiliz...</td>\n",
       "      <td>Alteração, Lei das Concessões de Serviços Públ...</td>\n",
       "      <td>Ofício nº 1416  (SF)                          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19098</td>\n",
       "      <td>PL</td>\n",
       "      <td>1992</td>\n",
       "      <td>3097</td>\n",
       "      <td>PL 3097/1992</td>\n",
       "      <td>Dispõe sobre a eleição de diretores de fundos ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMAS, ELEIÇÃO DIRETA, EMPREGADO, APOSENTADO,...</td>\n",
       "      <td>COMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E DE REDAÇÃ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20464</td>\n",
       "      <td>PL</td>\n",
       "      <td>2000</td>\n",
       "      <td>3927</td>\n",
       "      <td>PL 3927/2000</td>\n",
       "      <td>Altera a composição dos Tribunais Regionais do...</td>\n",
       "      <td>Altera a composição do TRT da 5ª região, 6ª re...</td>\n",
       "      <td>Alteração, Lei Federal, composição, Tribunal R...</td>\n",
       "      <td>COMISSÃO DE TRABALHO, DE ADMINISTRAÇÃO E SERVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20683</td>\n",
       "      <td>PL</td>\n",
       "      <td>1998</td>\n",
       "      <td>4117</td>\n",
       "      <td>PL 4117/1998</td>\n",
       "      <td>Dispõe sobre o acesso a ambientes de uso colet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Autorização, pessoa portadora de deficiência, ...</td>\n",
       "      <td>Câmara dos Deputados\\n           Departamento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20857</td>\n",
       "      <td>PL</td>\n",
       "      <td>1998</td>\n",
       "      <td>4395</td>\n",
       "      <td>PL 4395/1998</td>\n",
       "      <td>Estabelece as Diretrizes Nacionais de Defesa C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fixação, diretrizes, defesa civil, (Sindec), d...</td>\n",
       "      <td>- 1 - \\nCOMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57104</th>\n",
       "      <td>2358873</td>\n",
       "      <td>PL</td>\n",
       "      <td>2023</td>\n",
       "      <td>2233</td>\n",
       "      <td>PL 2233/2023</td>\n",
       "      <td>Altera o parágrafo único do art. 71 do Código ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 \\n  \\n \\n \\n \\nCÂMARA DOS DEPUTADOS \\nPROJET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57105</th>\n",
       "      <td>2358874</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>3616</td>\n",
       "      <td>PL 3616/2019</td>\n",
       "      <td>Altera a Lei nº 9.503, de 23 de setembro de 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 9.503, de 23 de setembro\\nde 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57106</th>\n",
       "      <td>2358875</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>1822</td>\n",
       "      <td>PL 1822/2019</td>\n",
       "      <td>Altera a Lei nº 11.340, de 7 de agosto de 2006...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 11.340, de 7 de agosto de\\n200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57107</th>\n",
       "      <td>2358877</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>3815</td>\n",
       "      <td>PL 3815/2019</td>\n",
       "      <td>Altera a Lei nº 7.565, de 19 de dezembro de 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 7.565, de 19 de dezembro\\nde  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>2358878</td>\n",
       "      <td>PL</td>\n",
       "      <td>2019</td>\n",
       "      <td>3130</td>\n",
       "      <td>PL 3130/2019</td>\n",
       "      <td>Altera a Lei nº 13.675, de 11 de junho de 2018...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altera a Lei nº 13.675, de 11 de junho de\\n201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57109 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       codProposicao txtSiglaTipo  numAno  numNumero       txtNome  \\\n",
       "0              16357   PL            1999       1165  PL 1165/1999   \n",
       "1              19098   PL            1992       3097  PL 3097/1992   \n",
       "2              20464   PL            2000       3927  PL 3927/2000   \n",
       "3              20683   PL            1998       4117  PL 4117/1998   \n",
       "4              20857   PL            1998       4395  PL 4395/1998   \n",
       "...              ...          ...     ...        ...           ...   \n",
       "57104        2358873   PL            2023       2233  PL 2233/2023   \n",
       "57105        2358874   PL            2019       3616  PL 3616/2019   \n",
       "57106        2358875   PL            2019       1822  PL 1822/2019   \n",
       "57107        2358877   PL            2019       3815  PL 3815/2019   \n",
       "57108        2358878   PL            2019       3130  PL 3130/2019   \n",
       "\n",
       "                                               txtEmenta  \\\n",
       "0      Altera dispositivo da Lei nº 8.987, de 13 de f...   \n",
       "1      Dispõe sobre a eleição de diretores de fundos ...   \n",
       "2      Altera a composição dos Tribunais Regionais do...   \n",
       "3      Dispõe sobre o acesso a ambientes de uso colet...   \n",
       "4      Estabelece as Diretrizes Nacionais de Defesa C...   \n",
       "...                                                  ...   \n",
       "57104  Altera o parágrafo único do art. 71 do Código ...   \n",
       "57105  Altera a Lei nº 9.503, de 23 de setembro de 19...   \n",
       "57106  Altera a Lei nº 11.340, de 7 de agosto de 2006...   \n",
       "57107  Altera a Lei nº 7.565, de 19 de dezembro de 19...   \n",
       "57108  Altera a Lei nº 13.675, de 11 de junho de 2018...   \n",
       "\n",
       "                                     txtExplicacaoEmenta  \\\n",
       "0      Estabelece que as concessionárias disponibiliz...   \n",
       "1                                                    NaN   \n",
       "2      Altera a composição do TRT da 5ª região, 6ª re...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "57104                                                NaN   \n",
       "57105                                                NaN   \n",
       "57106                                                NaN   \n",
       "57107                                                NaN   \n",
       "57108                                                NaN   \n",
       "\n",
       "                                            txtIndexacao  \\\n",
       "0      Alteração, Lei das Concessões de Serviços Públ...   \n",
       "1      NORMAS, ELEIÇÃO DIRETA, EMPREGADO, APOSENTADO,...   \n",
       "2      Alteração, Lei Federal, composição, Tribunal R...   \n",
       "3      Autorização, pessoa portadora de deficiência, ...   \n",
       "4      Fixação, diretrizes, defesa civil, (Sindec), d...   \n",
       "...                                                  ...   \n",
       "57104                                                NaN   \n",
       "57105                                                NaN   \n",
       "57106                                                NaN   \n",
       "57107                                                NaN   \n",
       "57108                                                NaN   \n",
       "\n",
       "                                          txtInteiroTeor  \n",
       "0      Ofício nº 1416  (SF)                          ...  \n",
       "1      COMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E DE REDAÇÃ...  \n",
       "2      COMISSÃO DE TRABALHO, DE ADMINISTRAÇÃO E SERVI...  \n",
       "3      Câmara dos Deputados\\n           Departamento ...  \n",
       "4      - 1 - \\nCOMISSÃO DE CONSTITUIÇÃO E JUSTIÇA E D...  \n",
       "...                                                  ...  \n",
       "57104  1 \\n  \\n \\n \\n \\nCÂMARA DOS DEPUTADOS \\nPROJET...  \n",
       "57105  Altera a Lei nº 9.503, de 23 de setembro\\nde 1...  \n",
       "57106  Altera a Lei nº 11.340, de 7 de agosto de\\n200...  \n",
       "57107  Altera a Lei nº 7.565, de 19 de dezembro\\nde  ...  \n",
       "57108  Altera a Lei nº 13.675, de 11 de junho de\\n201...  \n",
       "\n",
       "[57109 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d704396a",
   "metadata": {},
   "source": [
    "## Sem pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103b42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecf9023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txtNome</th>\n",
       "      <th>txtEmenta</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PL 1165/1999</td>\n",
       "      <td>Altera dispositivo da Lei nº 8.987, de 13 de f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL 3097/1992</td>\n",
       "      <td>Dispõe sobre a eleição de diretores de fundos ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL 3927/2000</td>\n",
       "      <td>Altera a composição dos Tribunais Regionais do...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PL 4117/1998</td>\n",
       "      <td>Dispõe sobre o acesso a ambientes de uso colet...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PL 4395/1998</td>\n",
       "      <td>Estabelece as Diretrizes Nacionais de Defesa C...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57104</th>\n",
       "      <td>PL 2233/2023</td>\n",
       "      <td>Altera o parágrafo único do art. 71 do Código ...</td>\n",
       "      <td>57104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57105</th>\n",
       "      <td>PL 3616/2019</td>\n",
       "      <td>Altera a Lei nº 9.503, de 23 de setembro de 19...</td>\n",
       "      <td>57105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57106</th>\n",
       "      <td>PL 1822/2019</td>\n",
       "      <td>Altera a Lei nº 11.340, de 7 de agosto de 2006...</td>\n",
       "      <td>57106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57107</th>\n",
       "      <td>PL 3815/2019</td>\n",
       "      <td>Altera a Lei nº 7.565, de 19 de dezembro de 19...</td>\n",
       "      <td>57107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57108</th>\n",
       "      <td>PL 3130/2019</td>\n",
       "      <td>Altera a Lei nº 13.675, de 11 de junho de 2018...</td>\n",
       "      <td>57108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            txtNome                                          txtEmenta     id\n",
       "0      PL 1165/1999  Altera dispositivo da Lei nº 8.987, de 13 de f...      0\n",
       "1      PL 3097/1992  Dispõe sobre a eleição de diretores de fundos ...      1\n",
       "2      PL 3927/2000  Altera a composição dos Tribunais Regionais do...      2\n",
       "3      PL 4117/1998  Dispõe sobre o acesso a ambientes de uso colet...      3\n",
       "4      PL 4395/1998  Estabelece as Diretrizes Nacionais de Defesa C...      4\n",
       "...             ...                                                ...    ...\n",
       "57104  PL 2233/2023  Altera o parágrafo único do art. 71 do Código ...  57104\n",
       "57105  PL 3616/2019  Altera a Lei nº 9.503, de 23 de setembro de 19...  57105\n",
       "57106  PL 1822/2019  Altera a Lei nº 11.340, de 7 de agosto de 2006...  57106\n",
       "57107  PL 3815/2019  Altera a Lei nº 7.565, de 19 de dezembro de 19...  57107\n",
       "57108  PL 3130/2019  Altera a Lei nº 13.675, de 11 de junho de 2018...  57108\n",
       "\n",
       "[57109 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083fc915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={'txtEmenta': 'contents'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf268e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"sem_pre_processamento_emenda/sem_pre_processamento.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f3d73",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498a94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b630f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c496976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0885490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1b4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [word for word in terms if word not in stopwords]\n",
    "    terms = \" \".join(terms)\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a87469",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"contents\"] = dados1[\"contents\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765072cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a625648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 28.698999\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d039a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"lower_remocao_punctuation_acentuacao_stopwords_emenda/pre_processamento_lower_remocao_punctuation_acentuacao_stopwords.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb475daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Savoy:\n",
    "\n",
    "    def __removeAllPTAccent(self, old_word):\n",
    "        word = list(old_word)\n",
    "        len_word = len(word)-1\n",
    "        for i in range(len_word, -1, -1):\n",
    "            if word[i] == 'ä':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'â':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'à':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'á':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'ã':\n",
    "                word[i] = 'a'\n",
    "            if word[i] == 'ê':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'é':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'è':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'ë':\n",
    "                word[i] = 'e'\n",
    "            if word[i] == 'ï':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'î':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'ì':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'í':\n",
    "                word[i] = 'i'\n",
    "            if word[i] == 'ü':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'ú':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'ù':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'û':\n",
    "                word[i] = 'u'\n",
    "            if word[i] == 'ô':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ö':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ó':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ò':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'õ':\n",
    "                word[i] = 'o'\n",
    "            if word[i] == 'ç':\n",
    "                word[i] = 'c'\n",
    "\n",
    "        new_word = \"\".join(word)\n",
    "        return new_word\n",
    "\n",
    "    def __finalVowelPortuguese(self, word):\n",
    "        len_word = len(word)\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 'e' or word[-1] == 'a' or word[-1] == 'o':\n",
    "                word = word[:-1]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __remove_PTsuffix(self, word):\n",
    "        len_word = len(word)\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'e' and (word[-3] == 'r' or word[-3] == 's' or word[-3] == 'z' or word[-3] == 'l'):\n",
    "                word = word[:-2]\n",
    "                return word\n",
    "        if len_word > 2:\n",
    "            if word[-1] == 's' and word[-2] == 'n':\n",
    "                new_word = list(word)\n",
    "                new_word[-2] = 'm'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if (word[-1] == 's' and word[-2] == 'i') and (word[-3] == 'e' or word[-3] == 'é'):\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'e'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'i' and word[-3] == 'a':\n",
    "                new_word = list(word)\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'i' and word[-3] == 'ó':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'o'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 3:\n",
    "            if word[-1] == 's' and word[-2] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                return sing\n",
    "\n",
    "        if len_word > 2:\n",
    "            if word[-1] == 's' and word[-2] == 'e' and word[-3] == 'õ':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'ã'\n",
    "                new_word[-2] = 'o'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "            if word[-1] == 's' and word[-2] == 'e' and word[-3] == 'ã':\n",
    "                new_word = list(word)\n",
    "                new_word[-2] = 'o'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "        if len_word > 5:\n",
    "            if word[-1] == 'e' and word[-2] == 't' and word[-3] == 'n' and word[-4] == 'e' and word[-5] == 'm':\n",
    "                word = word[:-5]\n",
    "                return word\n",
    "\n",
    "        if len_word > 2:\n",
    "            if word[-1] == 's':\n",
    "                word = word[:-1]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __normFemininPortuguese(self, word):\n",
    "\n",
    "        len_word = len(word)\n",
    "\n",
    "        if len_word < 3 or word[-1] != 'a':\n",
    "            return word\n",
    "\n",
    "        if len_word > 6:\n",
    "\n",
    "            if word[-2] == 'h' and word[-3] == 'n' and word[-4] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'c' and word[-3] == 'a' and word[-4] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'r' and word[-3] == 'i' and word[-4] == 'e':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "        if len_word > 5:\n",
    "            if word[-2] == 'n' and word[-3] == 'o':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'ã'\n",
    "                new_word[-2] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                masc = masc[:-1]\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'r' and word[-3] == 'o':\n",
    "                word = word[:-1]\n",
    "                return word\n",
    "\n",
    "            if word[-2] == 's' and word[-3] == 'o':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 's' and word[-3] == 'e':\n",
    "                new_word = list(word)\n",
    "                new_word[-3] = 'ê'\n",
    "                masc = \"\".join(new_word)\n",
    "                masc = masc[:-1]\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'c' and word[-3] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'd' and word[-3] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'd' and word[-3] == 'a':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'v' and word[-3] == 'i':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'm' and word[-3] == 'a':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "            if word[-2] == 'n':\n",
    "                new_word = list(word)\n",
    "                new_word[-1] = 'o'\n",
    "                masc = \"\".join(new_word)\n",
    "                return masc\n",
    "\n",
    "        return word\n",
    "\n",
    "    def stem(self, word):\n",
    "        len_word = len(word)\n",
    "        if len_word > 2:\n",
    "            word = self.__remove_PTsuffix(word)\n",
    "            word = self.__normFemininPortuguese(word)\n",
    "            word = self.__finalVowelPortuguese(word)\n",
    "            word = self.__removeAllPTAccent(word)\n",
    "\n",
    "        return word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce468c",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword + stemming (RSLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9280ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e60f8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad9f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)\n",
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8893580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLPStemmer()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "        \n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c95cb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a9b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"contents\"] = dados1[\"contents\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f517bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85ed873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 107.814990\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f13c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"rslp_full_emenda/pre_processamento_rslp_full.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773aaec",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword + stemming (Savoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57b25bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa08730",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5acc76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)\n",
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5353629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = Savoy()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "        \n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f008e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8e81416",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"contents\"] = dados1[\"contents\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "518b261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29aaecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 32.169002\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1276ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"savoy_full_emenda/pre_processamento_savoy_full.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67b784",
   "metadata": {},
   "source": [
    "# Word n-gram + pré processamento básico + rslp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61d656",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação, acentuação e stopword + unigram + bigram (rslp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c0119e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f141f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9056053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)\n",
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a21e143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLPStemmer()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    ngram = []\n",
    "    ngram_1 = list(ngrams(terms, 1))\n",
    "    ngram_2 = list(ngrams(terms, 2))\n",
    "    for w in ngram_1:\n",
    "        ngram.append(w[0])\n",
    "        \n",
    "    for w in ngram_2:\n",
    "        string = w[0] + \"_\" + w[1]\n",
    "        ngram.append(string)\n",
    "    \n",
    "    return \" \".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31e02076",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "515d32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"contents\"] = dados1[\"contents\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64fbf699",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26ee6847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 104.545997\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1af91ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"unigram_bigram_rslp_full_emenda/pre_processamento_unigram_bigram_rslp_full.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b55ad0",
   "metadata": {},
   "source": [
    "# Word n-gram + pré processamento básico + Savoy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907b296",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação, acentuação e stopword + unigram + bigram (savoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f09d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f264dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33c2f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adc1f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = Savoy()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    ngram = []\n",
    "    ngram_1 = list(ngrams(terms, 1))\n",
    "    ngram_2 = list(ngrams(terms, 2))\n",
    "    for w in ngram_1:\n",
    "        ngram.append(w[0])\n",
    "        \n",
    "    for w in ngram_2:\n",
    "        string = w[0] + \"_\" + w[1]\n",
    "        ngram.append(string)\n",
    "    \n",
    "    return \" \".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf0add04",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e39e6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"txtEmenta\"] = dados1[\"txtEmenta\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e11e6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f2569ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 33.357001\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5af199ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94183a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"unigram_bigram_savoy_full_emenda/pre_processamento_unigram_bigram_savoy_full.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf54545",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação + remoção de acentuação e remoção de stopword + stemming (RSLP_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5d06c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSLP_S:\n",
    "    def __plural_reduction(self, word):\n",
    "        excep = [\"lápis\",\"cais\",\"mais\",\"crúcis\",\"biquínis\",\"pois\",\"depois\",\"dois\",\"leis\" ]\n",
    "        excep_s = [\"aliás\",\"pires\",\"lápis\",\"cais\",\"mais\",\"mas\",\"menos\", \"férias\",\"fezes\",\"pêsames\",\"crúcis\",\"gás\", \"atrás\",\"moisés\",\"através\",\"convés\",\"ês\", \"país\",\"após\",\"ambas\",\"ambos\",\"messias\"]\n",
    "\n",
    "        len_word = len(word)\n",
    "        new_word = list(word)\n",
    "\n",
    "        if len_word >= 3:\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'n':\n",
    "                new_word[-2] = 'm'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'õ':\n",
    "                new_word[-3] = 'ã'\n",
    "                new_word[-2] = 'o'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return  sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'ã':\n",
    "                if word == 'mães':\n",
    "                    word = word[:-1]\n",
    "                    return word\n",
    "                else:\n",
    "                    new_word[-2] = 'o'\n",
    "                    sing = \"\".join(new_word)\n",
    "                    sing = sing[:-1]\n",
    "                    return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'a':\n",
    "                if word != 'cais' and word != 'mais':\n",
    "                    new_word[-2] = 'l'\n",
    "                    sing = \"\".join(new_word)\n",
    "                    sing = sing[:-1]\n",
    "                    return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'é':\n",
    "                new_word[-3] = 'e'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'e':\n",
    "                new_word[-3] = 'e'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i' and new_word[-3] == 'ó':\n",
    "                new_word[-3] = 'o'\n",
    "                new_word[-2] = 'l'\n",
    "                sing = \"\".join(new_word)\n",
    "                sing = sing[:-1]\n",
    "                return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'i':\n",
    "                if word not in excep:\n",
    "                    new_word[-1] = 'l'\n",
    "                    sing = \"\".join(new_word)\n",
    "                    return sing\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'l':\n",
    "                word = word[:-2]\n",
    "                return word\n",
    "\n",
    "            if new_word[-1] == 's' and new_word[-2] == 'e' and new_word[-3] == 'r':\n",
    "                word = word[:-2]\n",
    "                return word\n",
    "\n",
    "            if new_word[-1] == 's':\n",
    "                if word not in excep_s:\n",
    "                    word = word[:-1]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def stem(self, word):\n",
    "        word = self.__plural_reduction(word)\n",
    "\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5293436",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d66d37cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f85fc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)\n",
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e344281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLP_S()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "        \n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06652cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80c0dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"contents\"] = dados1[\"contents\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fba649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f8bae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 26.560001\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae919cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"rslps_full_emenda/pre_processamento_rslps_full.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6817f5",
   "metadata": {},
   "source": [
    "## Letra mínuscula + remoção de pontuação, acentuação e stopword + unigram + bigram (RSLP_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1e60c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"base_20230428_douglas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "296cf140",
   "metadata": {},
   "outputs": [],
   "source": [
    "colId = range(len(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c32df674",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[[\"txtNome\",\"txtEmenta\"]]\n",
    "dados1 = dados.assign(id=colId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ab5aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = str(txt)\n",
    "    txt = _remove_acentos(txt)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords.extend(list(punctuation))\n",
    "\n",
    "    stemmer = RSLP_S()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    terms = tokenizer.tokenize(txt.lower())\n",
    "    terms = [stemmer.stem(word) for word in terms if word not in stopwords]\n",
    "    \n",
    "    ngram = []\n",
    "    ngram_1 = list(ngrams(terms, 1))\n",
    "    ngram_2 = list(ngrams(terms, 2))\n",
    "    for w in ngram_1:\n",
    "        ngram.append(w[0])\n",
    "        \n",
    "    for w in ngram_2:\n",
    "        string = w[0] + \"_\" + w[1]\n",
    "        ngram.append(string)\n",
    "    \n",
    "    return \" \".join(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "035ffb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04710005",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1[\"txtEmenta\"] = dados1[\"txtEmenta\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1d13b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5f1d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração: 26.386986\n"
     ]
    }
   ],
   "source": [
    "print(\"Duração: %f\" %(d-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c62db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1 = dados1.rename(columns={\"txtEmenta\":\"contents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "425b5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados1.to_json(\"unigram_bigram_rslps_full_emenda/pre_processamento_unigram_bigram_rslps_full.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bbc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
